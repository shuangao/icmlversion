\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{lowe1999object}
\citation{bay2006surf}
\citation{dalal2005histograms}
\citation{krizhevsky2012imagenet}
\citation{zeiler2014visualizing}
\citation{simonyan2014very}
\citation{szegedy2014going}
\citation{zeiler2014visualizing}
\citation{Chatfield14}
\citation{jia2014caffe}
\citation{srivastava2014dropout}
\citation{linNiN}
\citation{szegedy2014going}
\citation{kawano14c}
\citation{bossard14}
\newlabel{exp}{{2}{2}{}{section.2}{}}
\newlabel{incept}{{1}{2}{Inception Cell. $n\times n$ stands for size $n$ receptive field, $n\times n\_reduce$ stands for the $1\times 1$ convolutional layer before the $n\times n$ convolution layer and $pool\_proj$ is another $1\times 1$ convolutional layer after the MAX pooling layer. The output layer concatenates all its input layers}{figure.1}{}}
\citation{agrawal2014analyzing}
\citation{glorot2010understanding}
\citation{bossard14}
\citation{singh2012unsupervised}
\citation{Kawano:2014}
\newlabel{discuss}{{3}{3}{}{section.3}{}}
\newlabel{tab:ft}{{1}{3}{Top-5 Accuracy in percent on fine-tuned, ft-last and scratch model for two architectures}{table.1}{}}
\newlabel{tab:256}{{3}{3}{Accuracy compared to other method on Food-256 dataset in percent}{table.3}{}}
\newlabel{tab:101}{{2}{4}{Top-1 accuracy compared to other methods on Food-101 dataset in percent}{table.2}{}}
\newlabel{fig:sashimi}{{2}{4}{Visualization of some feature maps of different GoogLeNet models in different layers for the same input image. 64 feature maps of each layer are shown. Conv1 is the first convolutional layer and Inception\_5b is the last convolutional layer}{figure.2}{}}
\newlabel{relu}{{1}{4}{}{equation.3.1}{}}
\citation{NIPS2014_Zhou}
\citation{langley00}
\bibdata{research}
\bibcite{agrawal2014analyzing}{{1}{2014}{{Agrawal et~al.}}{{Agrawal, Girshick, and Malik}}}
\bibcite{bay2006surf}{{2}{2006}{{Bay et~al.}}{{Bay, Tuytelaars, and Van~Gool}}}
\bibcite{bossard14}{{3}{2014}{{Bossard et~al.}}{{Bossard, Guillaumin, and Van~Gool}}}
\bibcite{Chatfield14}{{4}{2014}{{Chatfield et~al.}}{{Chatfield, Simonyan, Vedaldi, and Zisserman}}}
\newlabel{tab:cosg}{{4}{6}{Cosine similarity of the inceptions between fine-tuned models and pre-trained model for GoogLeNet}{table.4}{}}
\newlabel{tab:cosa}{{5}{6}{Cosine similarity of the layers between fine-tuned models and pre-trained model for AlexNet}{table.5}{}}
\newlabel{tab:addlabel}{{6}{6}{Sparsity of the output for each unit in GoogLeNet inception for training data from Food101 in percent}{table.6}{}}
\bibcite{dalal2005histograms}{{5}{2005}{{Dalal \& Triggs}}{{Dalal and Triggs}}}
\bibcite{glorot2010understanding}{{6}{2010}{{Glorot \& Bengio}}{{Glorot and Bengio}}}
\bibcite{jia2014caffe}{{7}{2014}{{Jia et~al.}}{{Jia, Shelhamer, Donahue, Karayev, Long, Girshick, Guadarrama, and Darrell}}}
\bibcite{kawano14c}{{8}{2014{a}}{{Kawano \& Yanai}}{{Kawano and Yanai}}}
\bibcite{Kawano:2014}{{9}{2014{b}}{{Kawano \& Yanai}}{{Kawano and Yanai}}}
\bibcite{krizhevsky2012imagenet}{{10}{2012}{{Krizhevsky et~al.}}{{Krizhevsky, Sutskever, and Hinton}}}
\bibcite{linNiN}{{11}{2013}{{Lin et~al.}}{{Lin, Chen, and Yan}}}
\bibcite{lowe1999object}{{12}{1999}{{Lowe}}{{}}}
\bibcite{simonyan2014very}{{13}{2014}{{Simonyan \& Zisserman}}{{Simonyan and Zisserman}}}
\bibcite{singh2012unsupervised}{{14}{2012}{{Singh et~al.}}{{Singh, Gupta, and Efros}}}
\bibcite{srivastava2014dropout}{{15}{2014}{{Srivastava et~al.}}{{Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov}}}
\bibcite{szegedy2014going}{{16}{2014}{{Szegedy et~al.}}{{Szegedy, Liu, Jia, Sermanet, Reed, Anguelov, Erhan, Vanhoucke, and Rabinovich}}}
\bibcite{zeiler2014visualizing}{{17}{2014}{{Zeiler \& Fergus}}{{Zeiler and Fergus}}}
\bibcite{NIPS2014_Zhou}{{18}{2014}{{Zhou et~al.}}{{Zhou, Lapedriza, Xiao, Torralba, and Oliva}}}
\bibstyle{icml2015}
\newlabel{tab:cross}{{7}{7}{Top5 Accuracy for transferring from Food101 to subset of Food256 in percent}{table.7}{}}
