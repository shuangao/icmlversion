Recognizing the objects in the world is the most fundamental function for human to understand the world the whole procedure of which only takes a few tens of milliseconds for human brain.
Recently, Convolutional Neural Network (CNN) shows its potential to replace the human engineered features, such as SIFT \cite{lowe1999object}, SURF \cite{bay2006surf} and HOG \cite{dalal2005histograms} etc, in real object recognition tasks. The success of CNNs on large scale image set started from Krizhevsky et al and their 8 layer model AlexNet in 2012 ImageNet Large-Scale Visual Recognition Challenge (ILSVRC2012), reaching a top-5 accuracy at 83\% \cite{krizhevsky2012imagenet}. Since then, many attempts have been made to improve the architecture of Krizhevsky.
By reducing the size of the receptive field and stride, Zeiler and Fergus improve AlexNet by 1.7\% on top 5 accuracy \cite{zeiler2014visualizing}. With the help of high performances computing systems, such as GPU and large scale distributed clusters, it is possible for researchers to explore larger and more complex architecture. By both adding extra convolutional layers between two pooling layers and reducing the receptive window size, Simonyan and Zisserman built a 19 layer very deep CNN and achieved 92.5\% top-5 accuracy \cite{simonyan2014very}.

After the AlexNet-like deep CNNs won ILSVRC2012 and ILSVRC2013, Szegedy et al built a 22 layers deep network, called GoogLeNet and won the 1st prize on ILSVRC2014 for 93.33\% top-5 accuracy, almost as good as human annotation\cite{szegedy2014going}. Different from AlexNet-like architecture, GoogLeNet shows another trend of designing deep CNN with many $1\times 1$ receptive field. However, its unique architecture has not been widely studied and few result can be found for applying GoogLeNet on other benchmark datasets.

Unlike the local features such as SIFT or SURF, which present an intuitive interpretation of spatial property%that is invariant with some transformations such as scaling and rotation
, we still don't have enough knowledge to fully understand the visual features of CNN learned in each layer.
%Training a large deep CNN on real recognition problem is always a complicated task. The model contains hundreds of millions of parameters to learn and lots of hyper-parameters that can affect its performance.
However, the truth that deep CNN outperforms other shallow models by a large margin in some real image recognition tasks encourages researchers to build deep architecture with powerful high performance hardware and larger datasets. With the help of high performance GPU clusters and data argumentation, people are more enthusiastic to explore bigger networks on complex recognition problems without much interpretation which makes other researchers difficult to understand the advantages of these architectures and explore their own ones.

Since these CNN models are trained on a very large image dataset and can learn hierarchical features, they have strong generalization ability and can be applied in many other scenarios. Applying the pre-trained model from ImageNet dataset on other object recognition benchmark datasets shows some impressive results.
Zeiler et al. applied their pre-trained model on Caltech-256 with just 15 instances per class to fine-tune the model and improved the previous state-of-the-art in which about 60 instances are used for training, by almost 10\% \cite{zeiler2014visualizing}.
Chatfield et al used their pre-trained model on VOC2007 dataset and outperformed the previous state-of-the-art by 0.9\% \cite{Chatfield14}.
Few results have been shown related to the transfer learning performance of deep CNN on a more challenging and specific real world recognition problem.

In this paper, we apply two kinds of deep CNN architecture, AlexNet and GoogLeNet, on a specific real recognition problem, food recognition, and discuss some tricks in fine-tuning the existing CNN architectures on this problem. To our best knowledge, not much work has done to discuss the architecture of GoogLeNet while the architecture of AlexNet has been widely studied and improved. Also, no work has been found to compare two deep CNNs with different architectures. By comparing some statistics of the weights and neuron responses of these two architectures, we find that the $1\times 1$ small receptive field used in GoogLeNet can improve both computational and training efficiency which leads to its success.
Also, we conduct several experiments to stimulate a real world scenario when the training labeled data is rare. The results reveal that deep CNN can work well while transferring knowledge from general recognition task to specific one in this scenario. We achieve 95\% accuracy trained on full dataset while just utilizing half of the dataset.

The rest of this paper is organized as follow: in Section \ref{exp}, the two food image datasets and two deep CNN architectures are introduced. In Section \ref{discuss}, some experimental results are shown and we also compare the performance between the deep CNNs as well as some traditional methods on these two datasets. And some discussion of the Inception's architecture and statistics are shown in Section \ref{discuss}. We also show some fine-tuning results when the training examples are rare for each class.
